{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PB1DHklOmsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_QaUhwEOpN0",
        "colab_type": "code",
        "outputId": "f092f8a5-5591-46cf-cf53-d524463234b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8mhpGO9w4XZ",
        "colab_type": "code",
        "outputId": "8f2b6875-e1a6-45e9-b1c5-dc51cf57ca4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import precision_score , recall_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def preprocess(gtzan_spectrograms, gtzan_labels):\n",
        "    #trainingData = np.concatenate((benchmark_spectrograms, gtzan_spectrograms), axis=0)\n",
        "    #label = np.concatenate((benchmark_labels, gtzan_labels), axis=0)\n",
        "    trainingData = gtzan_spectrograms\n",
        "    label = gtzan_labels\n",
        "    print(len(trainingData))\n",
        "    print(len(label))\n",
        "    one_hot_label = []\n",
        "    for k in label:\n",
        "        if k == 0:\n",
        "            one_hot_label.append([1, 0, 0, 0, 0])\n",
        "        if k == 1:\n",
        "            one_hot_label.append([0, 1, 0, 0, 0])\n",
        "        if k == 2:\n",
        "            one_hot_label.append([0, 0, 1, 0, 0])\n",
        "        if k == 3:\n",
        "            one_hot_label.append([0, 0, 0, 1, 0])\n",
        "        if k == 4:\n",
        "            one_hot_label.append([0, 0, 0, 0, 1])\n",
        "\n",
        "    x_train, x_validation, y_train, y_validation = train_test_split(trainingData, one_hot_label,train_size=4070, test_size=453,shuffle=True)\n",
        "    x_test, x_validation, y_test, y_validation = train_test_split(x_validation,y_validation, train_size=226, test_size=227, shuffle=True)\n",
        "\n",
        "    test_label = []\n",
        "    for i in list(y_test):\n",
        "        if i == [1, 0, 0, 0, 0]:\n",
        "            test_label.append(0)\n",
        "        if i == [0, 1, 0, 0, 0]:\n",
        "            test_label.append(1)\n",
        "        if i == [0, 0, 1, 0, 0]:\n",
        "            test_label.append(2)\n",
        "        if i == [0, 0, 0, 1, 0]:\n",
        "            test_label.append(3)\n",
        "        if i == [0, 0, 0, 0, 1]:\n",
        "            test_label.append(4)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    x_validation = np.array(x_validation)\n",
        "    x_test = np.array(x_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_validation = np.array(y_validation)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    return x_train, y_train, x_validation, y_validation, x_test, y_test,test_label\n",
        "\n",
        "# Use the following to load spectrograms:\n",
        "# modify name_suffix to choose dataset\n",
        "name_suffix = '_3_1024'\n",
        "#benchmark_spectrograms = pickle.load(open('drive/My Drive/mgc_dataset/Copy of benchmark_spectrograms' + name_suffix + '.p', 'rb'))\n",
        "gtzan_spectrograms = pickle.load(open('drive/My Drive/mgc_dataset/gtzan_spectrograms' + name_suffix + '.p', 'rb'))\n",
        "#benchmark_labels = pickle.load(open('drive/My Drive/mgc_dataset/benchmark_labels_3.p', 'rb'))\n",
        "gtzan_labels = pickle.load(open('drive/My Drive/mgc_dataset/gtzan_labels_3_1024.p', 'rb'))\n",
        "\n",
        "x_train, y_train, x_validation, y_validation, x_test, y_test,test_label = preprocess(gtzan_spectrograms, gtzan_labels)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_validation = np.expand_dims(x_validation, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "input_shape = (513, 128, 1)\n",
        "#input_shape = (257, 858, 1)\n",
        "num_category = 5\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(num_category, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history =model.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_validation, y_validation), callbacks=[callback])\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "plt.plot(history.history['acc'], label='accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "#evaluate the data set.\n",
        "predictTesting = model.predict_classes(np.asarray(x_test))\n",
        "print(\"Testing dataset confusion matrix: \\n\", confusion_matrix(test_label, predictTesting))\n",
        "print('Testing dataset Accuracy Score: \\n', accuracy_score(test_label, predictTesting))\n",
        "print('Testing dataset Report : \\n',classification_report(test_label, predictTesting))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4523\n",
            "4523\n",
            "Train on 4070 samples, validate on 227 samples\n",
            "Epoch 1/20\n",
            "4070/4070 [==============================] - 268s 66ms/sample - loss: 1.3877 - acc: 0.4774 - val_loss: 1.1684 - val_acc: 0.6211\n",
            "Epoch 2/20\n",
            "4070/4070 [==============================] - 266s 65ms/sample - loss: 1.1690 - acc: 0.6477 - val_loss: 1.0356 - val_acc: 0.7225\n",
            "Epoch 3/20\n",
            "4070/4070 [==============================] - 269s 66ms/sample - loss: 1.1216 - acc: 0.7039 - val_loss: 1.0913 - val_acc: 0.7621\n",
            "Epoch 4/20\n",
            "4070/4070 [==============================] - 268s 66ms/sample - loss: 1.0935 - acc: 0.7420 - val_loss: 1.0803 - val_acc: 0.7577\n",
            "Epoch 5/20\n",
            "4070/4070 [==============================] - 267s 66ms/sample - loss: 1.0162 - acc: 0.7776 - val_loss: 1.0816 - val_acc: 0.7841\n",
            "Epoch 6/20\n",
            "4070/4070 [==============================] - 265s 65ms/sample - loss: 0.9683 - acc: 0.8170 - val_loss: 1.0678 - val_acc: 0.8062\n",
            "Epoch 7/20\n",
            "1792/4070 [============>.................] - ETA: 2:26 - loss: 0.9172 - acc: 0.8304"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}